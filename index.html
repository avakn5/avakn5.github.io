<!doctype html>
<html>
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>Ava Kouhana's Homepage</title>
<link href="AboutPageAssets/styles/aboutPageStyle.css" rel="stylesheet" type="text/css">
<link rel="icon" type="image/png" href="https://www-media.stanford.edu/assets/favicon/favicon-32x32.png" sizes="32x32">

<!-- Fonts -->
<script>var __adobewebfontsappname__="dreamweaver"</script>
<script src="http://use.edgefonts.net/montserrat:n4:default;source-sans-pro:n2:default.js" type="text/javascript"></script>
</head>

<body alink="#282727" vlink="#9b9b9b" link="#9b9b9b">
<header>
  <!-- Profile photo -->
  <div class="profilePhoto">
    <img src="AboutPageAssets/images/profile1.jpg" alt="Ava Kouhana" width="259">
  </div>
  <!-- Identity details -->
  <section class="profileHeader">
    <h1>Ava Kouhana</h1>
    <h3>MS Student @ Stanford ICME (Computational and Mathematical Engineering)</h3>
    <hr>
    <p>
      I am an ICME master's degree student at Stanford University. Prior to Stanford, I spent six months conducting research at Harvard under the supervision of <a href="https://wang.hms.harvard.edu/about-us/" target="_blank">Dr. Mengyu Wang</a>, focusing primarily on Computer Vision tasks like Image Segmentation and Vision-Language Models. Before joining ICME, I had the opportunity to work for six months supervised by Stanford Professor <a href="https://med.stanford.edu/profiles/craig-levin" target="_blank">Dr. Craig Levin</a>, researching the application of Diffusion Models for image super-resolution.<br>
      
      My research interests primarily revolve around computer vision, deep learning, and generative AI, with a growing interest for 3D modeling and video generation.
    </p>
  </section>

  <!-- Social Links -->
  <aside class="socialNetworkNavBar">
    <div class="socialNetworkNav">
      <a href="mailto:akouhana@stanford.edu">
        <img src="AboutPageAssets/images/mail.png" alt="Email" width="30">
      </a>
    </div>
    <div class="socialNetworkNav">
      <a href="https://www.linkedin.com/in/ava-k-a56a90186" target="_blank">
        <img src="AboutPageAssets/images/LinkedIN.png" alt="LinkedIn" width="30">
      </a>
    </div>
    <div class="socialNetworkNav">
      <a href="https://github.com/avakn5" target="_blank">
        <img src="AboutPageAssets/images/github.png" alt="GitHub" width="30">
      </a>
    </div>
    <div class="socialNetworkNav">
      <a href="https://scholar.google.com/citations?user=nxESuB0AAAAJ&hl=fr" target="_blank">
        <img src="AboutPageAssets/images/scholar.jpg" alt="Google Scholar" width="30">
      </a>
    </div>
    <div class="socialNetworkNav">
      <a href="https://profiles.stanford.edu/ava-kouhana" target="_blank">
        <img src="AboutPageAssets/images/stanford-logo.png" alt="Stanford Profile" width="50">
      </a>
    </div>
  </aside>
</header>


<!-- Content -->
<section class="mainContent">

<section class="section2 github-projects">
  <h2 class="sectionTitle">Pinned GitHub Projects</h2>
  <hr class="sectionTitleRule">
  <div style="padding-left:40px;">
    <a href="https://github.com/avakn5/BPE-from-Scratch" target="_blank" style="text-decoration:none;">
      <img src="https://gh-card.dev/repos/avakn5/BPE_From_Stratch_CS336_Stanford.svg" alt="GitHub Project Card" style="border:0;">
    </a>
  </div>
</section>

  <!-- Publications -->
  <section class="section2">
    <h2 class="sectionTitle">Publications</h2>
    <hr class="sectionTitleRule">
    <hr class="sectionTitleRule2">

    <!-- FairSeg -->
    <div class="sectionContent">
      <img src="AboutPageAssets/images/fairseg-thumbnail.png" style="width:100%; object-fit:contain" alt="FairSeg">
    </div>
    <section class="section2Content">
      <h2 class="sectionContentTitle">FairSeg: A Large-Scale Medical Image Segmentation Dataset for Fairness Learning Using Segment Anything Model with Fair Error-Bound Scaling</h2>
      <h3 class="sectionContentSubTitle">Yu Tian*, Min Shi*, Yan Luo*, <b>Ava Kouhana</b>, Tobias Elze, Mengyu Wang</h3>
      <h3 class="sectionContentSubTitle"><em>International Conference on Learning Representations (ICLR), 2024</em></h3>
    </section>
    <aside class="externalResourcesNav">
      <div class="dropdown"><a href="https://arxiv.org/pdf/2311.02189" target="_blank">Paper</a></div>
      <div class="dropdown"><a href="https://github.com/Harvard-Ophthalmology-AI-Lab/FairSeg" target="_blank">Code</a></div>
      <div class="dropdown"><a href="https://drive.google.com/drive/folders/1tyhEhYHR88gFkVzLkJI4gE1BoOHoHdWZ?usp=sharing" target="_blank">Dataset</a></div>
    </aside>

    <br><br>

    <!-- FairCLIP -->
    <div class="sectionContent">
      <img src="AboutPageAssets/images/fairclip-thumbnail.png" style="width:100%; object-fit:contain" alt="FairCLIP">
    </div>
    <section class="section2Content">
      <h2 class="sectionContentTitle">FairCLIP: Harnessing Fairness in Vision-Language Learning</h2>
      <h3 class="sectionContentSubTitle">Yan Luo*, Min Shi*, Muhammad Osama Khan*, Muhammad Muneeb Afzal, Hao Huang, Shuaihang Yuan, Yu Tian, Luo Song, <b>Ava Kouhana</b>, Tobias Elze, Yi Fang, Mengyu Wang</h3>
      <h3 class="sectionContentSubTitle"><em>Conference on Computer Vision and Pattern Recognition (CVPR), 2024</em></h3>
    </section>
    <aside class="externalResourcesNav">
      <div class="dropdown"><a href="https://arxiv.org/pdf/2403.19949" target="_blank">Paper</a></div>
      <div class="dropdown"><a href="https://github.com/Harvard-Ophthalmology-AI-Lab/FairCLIP" target="_blank">Code</a></div>
      <div class="dropdown"><a href="https://drive.google.com/drive/u/1/folders/1bkeifigwOAfnsLvup9mJOSNeA3WsvA2l" target="_blank">Dataset</a></div>
    </aside>

    <br><br>

    <!-- IEEE Conference Papers -->
    <div class="sectionContent">
      <img src="AboutPageAssets/images/pet-attenuation-scatter-correction-diffusion.jpg" style="width:100%; object-fit:contain" alt="PET Attenuation">
    </div>
    <section class="section2Content">
      <h2 class="sectionContentTitle">Direct Generation of Attenuation and Scatter Correction of Brain PET Data Using a Conditional Latent Diffusion Model</h2>
      <h3 class="sectionContentSubTitle"><b>Ava Kouhana</b>, M. Jafaritadi, G. Chinn, C.S. Levin</h3>
      <h3 class="sectionContentSubTitle"><em>IEEE Nuclear Science Symposium and Medical Imaging Conference (NSS MIC), 2024</em></h3>
    </section>
    <aside class="externalResourcesNav">
      <div class="dropdown"><a href="https://ieeexplore.ieee.org/abstract/document/10657057" target="_blank">Paper</a></div>
      <div class="dropdown"><a href="AboutPageAssets/images/Ava_Kouhana_IEEE_NSS_MIC_denoising_Poster_2024.001.jpeg" target="_blank">Poster</a></div>
    </aside>

    <br><br>

    <div class="sectionContent">
      <img src="AboutPageAssets/images/figure70.jpg" style="width:100%; object-fit:contain" alt="Super-Resolution Reconstruction">
    </div>
    <section class="section2Content">
      <h2 class="sectionContentTitle">Super-Resolution Tomographic Image Reconstruction Using Latent Diffusion Models</h2>
      <h3 class="sectionContentSubTitle"><b>Ava Kouhana</b>, M. Jafaritadi, G. Chinn, C.S. Levin</h3>
      <h3 class="sectionContentSubTitle"><em>IEEE Nuclear Science Symposium and Medical Imaging Conference (NSS MIC), 2024</em></h3>
    </section>
    <aside class="externalResourcesNav">
      <div class="dropdown"><a href="https://ieeexplore.ieee.org/abstract/document/10656848" target="_blank">Paper</a></div>
      <div class="dropdown"><a href="AboutPageAssets/images/AvaKouhana_20th_Symposium.jpg" target="_blank">Poster</a></div>
    </aside>

  </section>

  <!-- Awards -->
  <section class="section2">
    <h2 class="sectionTitle">Grants & Awards</h2>
    <hr>
    <ul style="padding-left: 40px;">
      <li><b>Recipient of 2024 IEEE Nuclear Science, Medical Imaging Trainee Grant (NSS MIC)</b></li>
      <li><b>2nd place Outstanding Poster at the 20th anniversary of ICME Stanford Research Symposium</b></li>
    </ul>
  </section>

<footer>
  <br><br>
  <p class="footerDisclaimer" style="font-size:8px;">Template inspired by <a href="https://omerbt.github.io">Omer Bar Tal</a></p>
</footer>
</body>
</html>
